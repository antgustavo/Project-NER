{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "240ec09b",
   "metadata": {},
   "source": [
    "# Inicializa√ß√£o do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91595f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "import json\n",
    "from settings import API_KEY\n",
    "\n",
    "\n",
    "try:\n",
    "    llm  = ChatOllama(model=\"gemma3:27b\", temperature=0, base_url=\"http://192.168.133.192:11435\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao inicializar o Ollama. Certifique-se de que o Ollama est√° em execu√ß√£o e o modelo 'gemma3' est√° dispon√≠vel.\")\n",
    "    print(f\"Detalhes do erro: {e}\")\n",
    "    exit()\n",
    "\n",
    "# my_key = API_KEY\n",
    "# MODEL_NAME = \"gpt-3.5-turbo\"\n",
    "\n",
    "# my_proxy = \"http://silveiraagsd:Ccasj421%40@192.168.132.202:8080\"\n",
    "\n",
    "# proxies = {\n",
    "#     \"http://\": my_proxy,\n",
    "#     \"https://\": my_proxy,\n",
    "# }\n",
    "\n",
    "# try:\n",
    "#     llm = ChatOpenAI(api_key= my_key, \n",
    "#                    model=MODEL_NAME, \n",
    "#                    temperature=0,\n",
    "#                    client_kwargs = {\"proxies\": proxies}\n",
    "#                 )\n",
    "# except Exception as e:\n",
    "#     print(\"Erro ao inicializar o groq\")\n",
    "#     print(f\"Detalhes do erro: {e}\")\n",
    "#     exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b38c5cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Bom dia! üòä\\n\\nEspero que seu dia seja √≥timo! Em que posso te ajudar hoje?\\n', additional_kwargs={}, response_metadata={'model': 'gemma3:27b', 'created_at': '2025-06-02T10:31:55.772685428Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1400729703, 'load_duration': 28005802, 'prompt_eval_count': 11, 'prompt_eval_duration': 126018553, 'eval_count': 22, 'eval_duration': 1246123967, 'model_name': 'gemma3:27b'}, id='run--b1f37492-7be3-4972-8299-b10819919a2b-0', usage_metadata={'input_tokens': 11, 'output_tokens': 22, 'total_tokens': 33})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"bom dia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8c3d867",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_conll_data(filepath):\n",
    "    \"\"\"\n",
    "    Carrega dados de um ficheiro no formato CoNLL.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): O caminho para o ficheiro .txt.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Uma tupla contendo uma lista de frases (listas de palavras)\n",
    "               e uma lista de sequ√™ncias de etiquetas.\n",
    "    \"\"\"\n",
    "\n",
    "    setences, tag_sequences = [], []\n",
    "    current_words, current_tags = [], []\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if  line:  # Linha vazia\n",
    "                    if len(line.split()) == 2:\n",
    "                        word, tag = line.split()\n",
    "                        current_words.append(word)\n",
    "                        current_tags.append(tag)\n",
    "            else:\n",
    "                 if current_words:\n",
    "                    setences.append(current_words)\n",
    "                    tag_sequences.append(current_tags)\n",
    "                    current_words, current_tags = [], []\n",
    "    if current_words:\n",
    "        setences.append(current_words)\n",
    "        tag_sequences.append(current_tags)\n",
    "\n",
    "    return setences, tag_sequences\n",
    "\n",
    "\n",
    "palavras, tag = load_conll_data(\"test.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac971cf",
   "metadata": {},
   "source": [
    "# Defini√ß√£o dos Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72c587e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_text = \"\"\"\n",
    "\n",
    "Voc√™ √© um especialista em Reconhecimento de Entidades Nomeadas (NER) treinado para identificar e classificar entidades em textos jur√≠dicos brasileiros.\n",
    "Sua tarefa √© analisar o texto fornecido e retornar cada palavra (token) acompanhada de uma etiqueta NER no formato BIO.\n",
    "As etiquetas poss√≠veis s√£o:\n",
    "\n",
    "- O: Para palavras que n√£o pertencem a nenhuma entidade.\n",
    "- B-Organizacao: Para a primeira palavra em uma frase de uma entidade do tipo \"Organiza√ß√£o\" (ex: Minist√©rio P√∫blico, Tribunal de Justi√ßa).\n",
    "- I-Organizacao: Para palavras subsequentes dentro de uma frase para entidade do tipo \"Organiza√ß√£o\".\n",
    "- B-Jurisprudencia: Para a primeira palavra em uma frase de uma entidade do tipo \"Jurisprud√™ncia\" (ex: S√∫mula 385 STJ, Recurso Especial n¬∫ 1.234.567).\n",
    "- I-Jurisprudencia: Para palavras subsequentes dentro de uma frse para entidade do tipo \"Jurisprud√™ncia\".\n",
    "- B-Pessoa: Para a primeira palavra em uma frase de uma entidade do tipo \"Pessoa\" (ex: Jo√£o da Silva, Maria Oliveira).\n",
    "- I-Pessoa: Para palavras subsequentes dentro de uma frase para entidade do tipo \"Pessoa\".\n",
    "- B-Tempo: Para a primeira palavra em uma frase de uma entidade do tipo \"Tempo\" (ex: 01 de janeiro de 2023, segunda-feira, prazo de 15 dias).\n",
    "- I-Tempo: Para palavras subsequentes dentro de uma frase para entidade do tipo \"Tempo\".\n",
    "- B-Local: Para a primeira palavra em uma frase de uma entidade do tipo \"Local\" (ex: S√£o Paulo, Comarca de Campinas, Brasil).\n",
    "- I-Local: Para palavras subsequentes dentro de uma frase para entidade do tipo \"Local\".\n",
    "- B-Legislacao: Para a primeira palavra em uma frase de uma entidade do tipo \"Legisla√ß√£o\" (ex: C√≥digo Civil, Lei n¬∫ 8.666/93, Art. 5¬∫ da Constitui√ß√£o Federal).\n",
    "- I-Legislacao: Para palavras subsequentes dentro de uma frase para entidade do tipo \"Legisla√ß√£o\".\n",
    "\n",
    "A entrada ser√° uma lista de listas de string no seguinte formato:\n",
    "[\n",
    "    ['O', 'Dia', 'Est√°', 'Lindo', 'Hoje'],\n",
    "    ['O', 'Relator', 'Est√°', 'Ciente', 'Do', 'Contrato'],\n",
    "    ['No', 'caso', 'em', 'debate', 'nestes', 'autos', ',', 'a', 'guarda']\n",
    "    ['Eu', 'sou', 'uma', 'pessoa', 'muito', 'inteligente', '-', 'disse', 'o', 'homem']\n",
    "    ['O', 'arts','.','58','e','67', ',', 'Lei', '8666/94', ',' , '186', 'e', '927', 'do', 'C√≥digo', 'Civil', ')', '.' ]\n",
    "    ['Encontra-se', 'em', 'conson√¢ncia', 'com', 'o', 'fundamento', 'acolhido', 'pelo', 'STF']\n",
    "    ['Confiram-se', 'as', 'seguintes', 'decis√µes', ':', 'Rcl', '13941', 'MC', '/', ',' , 'Relator', 'Ministros', 'Cezar', 'Peluso', 'DJE', '31/08/2012']\n",
    "]\n",
    "\n",
    "A sa√≠da DEVE ser estritamente no formato, e apenas nesse formato e nada mais:\n",
    "{{\n",
    "\n",
    "    \"Frase1\": [\"O\", \"O\", \"O\", \"O\", \"B-TEMPO\"]\n",
    "    \"Frase2\": [\"O\", \"B-PESSOA\", \"O\", \"O\", \"O\"]\n",
    "    \"Frase3\": [\"O\",\"O\",\"O\",\"O\",\"O\",\"O\",\"O\",\"O\",\"O\"]\n",
    "    \"Frase4\": [\"B-PESSOA\", \"O\", \"O\", \"I-PESSOA\", \"O\", \"O\", \"O\", \"O\", \"O\", \"I-PESSOA\"]\n",
    "    \"Frase5\": [\"O\", \"B-LEGISLACAO\", \"I-LEGISLACAO\", \"I-LEGISLACAO\",\"I-LEGISLACAO\",\"I-LEGISLACAO\",\"I-LEGISLACAO\",\"I-LEGISLACAO\",\"I-LEGISLACAO\",\"O\",\"I-LEGISLACAO\",\"I-LEGISLACAO\",\"I-LEGISLACAO\",\"I-LEGISLACAO\",\"I-LEGISLACAO\",\"O\",\"O\"]\n",
    "    \"Frase6\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-ORGANIZA√á√ÉO\"]\n",
    "    \"Frase7\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"B-JURISPRUDENCIA\", \"I-JURISPRUDENCIA\", \"I-JURISPRUDENCIA\", \"I-JURISPRUDENCIA\", \"I-JURISPRUDENCIA\", \"O\", \"O\", \"O\", \"B-PESSOA\", \"I-PESSOA\", \"O\", \"B-TEMPO\"]\n",
    "}}\n",
    "\n",
    "Na qual cada posicao do vetor representa a respectiva entidade nomeada da frase. \n",
    "\n",
    "N√ÉO RESPONDA EM MARKDOWN, RESPONDA EM STRING SIMPLES\n",
    "\"\"\"\n",
    "\n",
    "user_prompt_text = \"\"\"Analise o seguinte texto e forne√ßa a classifica√ß√£o NER para cada palavra no formato especificado:\n",
    "TEXTO DE ENTRADA:\n",
    "{texto_entrada}\"\"\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt_text),\n",
    "    (\"user\", user_prompt_text)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a86d03a",
   "metadata": {},
   "source": [
    "# Cria√ß√£o da Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98f5b99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sa√≠da da LLM\n",
      "{\n",
      "    \"Frase1\": [\"O\", \"O\", \"O\", \"B-JURISPRUDENCIA\", \"I-JURISPRUDENCIA\", \"O\", \"O\", \"O\", \"B-PESSOA\", \"I-PESSOA\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-LEGISLACAO\", \"I-LEGISLACAO\", \"I-LEGISLACAO\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-TEMPO\", \"I-TEMPO\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-PESSOA\", \"I-PESSOA\", \"O\", \"O\"]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chain = prompt_template | llm | StrOutputParser()\n",
    "\n",
    "texto_exemplo = \"\"\"\n",
    "[\n",
    "   Frase1: ['N√∫mero', 'do', 'Ac√≥rd√£o', 'AC√ìRD√ÉO', '1160/2016', '-', 'PLEN√ÅRIO', 'Relator', 'AUGUSTO', 'NARDES', 'Processo', '006.010/2000-4', 'Tipo', 'de', 'processo', 'TOMADA', 'DE', 'CONTAS', 'SIMPLIFICADA', '(', 'TCSP', ')', 'Data', 'da', 'sess√£o', '11/05/2016', 'N√∫mero', 'da', 'ata', '16/2016', 'Relator', 'da', 'delibera√ß√£o', 'recorrida', 'Ministra', 'Ana', 'Arraes', '.']\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "try: \n",
    "    response = chain.invoke({\"texto_entrada\" : texto_exemplo})\n",
    "    print(\"Sa√≠da da LLM\")\n",
    "    print(response)\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao invocar a chain: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fbb827",
   "metadata": {},
   "source": [
    "# Cria√ß√£o da l√≥gica de tratamento das frases para LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "835fdd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_batch_for_llm(batch_sentences, start_index=1):\n",
    "    \"\"\"\n",
    "    Formata um lote de frases para a string de entrada esperada pelo LLM.\n",
    "    Args:\n",
    "        batch_sentences (list): Uma lista de frases (onde cada frase √© uma lista de palavras).\n",
    "        start_index (int): O √≠ndice inicial para nomear as frases (Frase1, Frase2, ...).\n",
    "    Returns:\n",
    "        str: A string formatada para o LLM.\n",
    "    \"\"\"\n",
    "    formatted_lines = []\n",
    "    for i, sentence_words in enumerate(batch_sentences):\n",
    "        # Escapar aspas simples dentro das palavras, se houver\n",
    "        escaped_sentence_words = [word.replace(\"'\", \"\\\\'\") for word in sentence_words]\n",
    "        formatted_lines.append(f\"    Frase{start_index + i}: {escaped_sentence_words}\")\n",
    "    \n",
    "    return \"[\\n\" + \",\\n\".join(formatted_lines) + \"\\n]\"\n",
    "\n",
    "\n",
    "def process_ner_in_batches(filepath, batch_size=10):\n",
    "    \"\"\"\n",
    "    Carrega frases, envia-as em lotes para o LLM para NER, e imprime os resultados.\n",
    "    \"\"\"\n",
    "    print(f\"A carregar frases do ficheiro: {filepath}\")\n",
    "    all_sentences, _ = load_conll_data(filepath) # N√£o precisamos das etiquetas originais aqui\n",
    "\n",
    "    if not all_sentences:\n",
    "        print(\"Nenhuma frase encontrada no ficheiro. A sair.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Total de frases carregadas: {len(all_sentences)}\")\n",
    "    \n",
    "    all_llm_classifications = {} # Para armazenar todas as classifica√ß√µes\n",
    "\n",
    "    for i in range(0, len(all_sentences), batch_size):\n",
    "        batch = all_sentences[i : i + batch_size]\n",
    "        # O start_index para format_batch_for_llm deve ser global para todo o ficheiro,\n",
    "        # n√£o relativo ao lote, para que as chaves no JSON de sa√≠da sejam √∫nicas\n",
    "        # e correspondam √† numera√ß√£o das frases no prompt (Frase1, Frase2, ... FraseN)\n",
    "        # No entanto, o prompt de exemplo sugere que o LLM pode lidar com a renumera√ß√£o por lote.\n",
    "        # Para simplificar e corresponder ao exemplo de sa√≠da no prompt, vamos numerar a partir de 1 para cada lote.\n",
    "        # Se quiser chaves globais, o start_index seria `i + 1`.\n",
    "        # Vamos seguir o exemplo do prompt e numerar a partir de 1 para cada chamada.\n",
    "        \n",
    "        # O identificador da frase deve ser √∫nico no JSON retornado pelo LLM.\n",
    "        # Se o LLM for instru√≠do a usar Frase1, Frase2... para cada lote,\n",
    "        # precisaremos mapear de volta para as frases originais.\n",
    "        # Vamos numerar globalmente para facilitar o mapeamento.\n",
    "        \n",
    "        formatted_input_string = format_batch_for_llm(batch, start_index= i + 1)\n",
    "        \n",
    "        print(f\"\\n--- A processar lote de frases: {i+1} a {i+len(batch)} ---\")\n",
    "        # print(\"Entrada formatada para o LLM:\")\n",
    "        # print(formatted_input_string) # Descomente para depura√ß√£o\n",
    "\n",
    "        try:\n",
    "            print(\"A enviar para o LLM...\")\n",
    "            response_str = chain.invoke({\"texto_entrada\": formatted_input_string})\n",
    "            \n",
    "            print(\"Resposta recebida do LLM (string):\")\n",
    "            print(response_str)\n",
    "\n",
    "            # Tentar analisar a resposta JSON\n",
    "            try:\n",
    "                # O LLM pode, por vezes, adicionar ```json ... ``` ou outro texto.\n",
    "                # Tentaremos encontrar o JSON dentro da string.\n",
    "                json_start = response_str.find('{')\n",
    "                json_end = response_str.rfind('}') + 1\n",
    "                if json_start != -1 and json_end != 0 and json_start < json_end:\n",
    "                    json_payload_str = response_str[json_start:json_end]\n",
    "                    llm_output_json = json.loads(json_payload_str)\n",
    "                    print(\"JSON analisado com sucesso:\")\n",
    "                    # print(json.dumps(llm_output_json, indent=4, ensure_ascii=False)) # Descomente para depura√ß√£o\n",
    "\n",
    "                    # Adicionar ao resultado global\n",
    "                    all_llm_classifications.update(llm_output_json)\n",
    "\n",
    "                    # Validar e imprimir classifica√ß√µes para este lote\n",
    "                    for sentence_key, predicted_tags in llm_output_json.items():\n",
    "                        # Extrair o √≠ndice num√©rico da chave \"FraseX\"\n",
    "                        try:\n",
    "                            original_sentence_index = int(sentence_key.replace(\"Frase\", \"\")) - 1\n",
    "                            if 0 <= original_sentence_index < len(all_sentences):\n",
    "                                original_sentence_words = all_sentences[original_sentence_index]\n",
    "                                if len(original_sentence_words) == len(predicted_tags):\n",
    "                                    print(f\"\\nClassifica√ß√µes para {sentence_key} (Frase original {original_sentence_index + 1}):\")\n",
    "                                    for word, tag in zip(original_sentence_words, predicted_tags):\n",
    "                                        print(f\"{word}\\t{tag}\")\n",
    "                                else:\n",
    "                                    print(f\"Erro: Discrep√¢ncia no n√∫mero de palavras e etiquetas para {sentence_key}.\")\n",
    "                                    print(f\"  Palavras ({len(original_sentence_words)}): {original_sentence_words}\")\n",
    "                                    print(f\"  Etiquetas ({len(predicted_tags)}): {predicted_tags}\")\n",
    "                            else:\n",
    "                                print(f\"Aviso: Chave de frase inesperada ou √≠ndice fora dos limites: {sentence_key}\")\n",
    "                        except ValueError:\n",
    "                            print(f\"Aviso: N√£o foi poss√≠vel extrair o √≠ndice da chave da frase: {sentence_key}\")\n",
    "                else:\n",
    "                    print(\"Erro: N√£o foi poss√≠vel encontrar um objeto JSON v√°lido na resposta do LLM.\")\n",
    "                    print(f\"Resposta completa: {response_str}\")\n",
    "\n",
    "            except json.JSONDecodeError as json_e:\n",
    "                print(f\"Erro ao analisar a resposta JSON do LLM: {json_e}\")\n",
    "                print(f\"String de resposta que causou o erro: '{response_str}'\")\n",
    "\n",
    "        except Exception as llm_e:\n",
    "            print(f\"Erro ao invocar a chain do LLM para o lote {i//batch_size + 1}: {llm_e}\")\n",
    "            # Continuar para o pr√≥ximo lote se houver um erro\n",
    "            continue\n",
    "    \n",
    "    print(\"\\n--- Processamento de todos os lotes conclu√≠do ---\")\n",
    "    # Pode fazer algo com all_llm_classifications aqui, como guardar num ficheiro.\n",
    "    # print(\"\\nTodas as classifica√ß√µes obtidas (formato JSON):\")\n",
    "    # print(json.dumps(all_llm_classifications, indent=4, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799d083d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A carregar frases do ficheiro: test.txt\n",
      "Total de frases carregadas: 1389\n",
      "\n",
      "--- A processar lote de frases: 1 a 10 ---\n",
      "A enviar para o LLM...\n"
     ]
    }
   ],
   "source": [
    "test_file_path = \"test.txt\"\n",
    "process_ner_in_batches(test_file_path, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
